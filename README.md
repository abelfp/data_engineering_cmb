# Data Engineering Capstone Project - Astrophysics Database

## {Project Title}

### Project Summary
--describe your project at a high level--

### Step 1: Scope the Project and Gather Data

#### Scope
Explain what you plan to do with the project in more detail. What data do you
use? What is your end solution look like? What tools did you use? etc.

#### Describe and Gather Data
Describe the data sets you're using. Where did it come from? What type of
information is included?

### Step 2: Explore and Access the Data

#### Explore the Data
Identify data quality issues, like missing values, duplicate data, etc.

#### Cleaning Steps
Document steps necessary to clean the data.

### Step 3: Define the Data Model

#### Conceptual Data Model
Map out the conceptual data model and explain why you chose that model.

#### Mapping Out Data Pipelines
List the steps necessary to pipeline the data into the chosen data model.

### Step 4: Run Pipelines to Model the Data

#### Create the Data Model
Build the data pipelines to create the data model.

#### Data Quality Checks
Explain the data quality you'll perform to ensure the pipeline ran as expected.

These could include:
- Integrity constraints on the relational database (e.g. unique key, data type,
  etc.)
- Unit tests for the scripts to ensure they are doing the right thing.
- Source/Count checks to ensure completeness.

#### Data Dictionary
Create a data dictionary for your data model. For each field, provide a brief
description of what the data is and where it came from. You can include the
data dictionary in the notebook or in a separate file.

### Step 5: Complete the Project Write Up
- Clearly state the rationale for the choice of tools and technologies for the
  project
- Propose how often the data should be updated and why.
- Write a description of how you would approach the problem differently under
  the following scenarios:
    - The data was increased by 100x.
    - The data populates a dashboard that must be updated on a daily basis by
      7am every day.
    - The database needed to be accessed by 100+ people.


